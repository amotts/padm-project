Needs:

Credit for reference: Pascal Spino and William B Mitchell

In 6 Degree configuration space. Can used euclidean geometry in 6 dof space. Will NOT mean linear or even necessarily good movement in end-effector space, but for simplicity, will use configuration space only and real world be dammned

- RRT
    - accept a start, goal
    - output a sequence of poses
    - detects collisions
    - find closest node
    - takes step
    - finds random point
    - cuttoff point -> failed

    Steps
    1) check goal and start locations for collisions with obstacles via collision function
    2) create list of rrt nodes
    3) limiting loop for number of iterations until fail
    4) take sample point
    5) find nearest node by using argmin of distance function
    6) get point step distance along line
    7) check point for collision with collision function
    8) if no collision: add to queue and check if is goal state. if so return path




    Notes:
    Did not include "extend" or consider any midway points, currently not limited by phsyical constraints on angle movements
    Need step function to find point one step away in direction of sample
    implemented a percentage goal: random percent of the time, select the goal as the sample, increases speed of finding target
        - in simple cartesian, when from 170 nodes explored with %=0.0 to ~50 nodes explored with %=0.33


Helper func todo:
    # dist_func 
    # take_step - linear scaling of each dimension
    # sample_func - provided 
    # collision_func - unclear exactly what its hitting. May need to include or discount certain obstacles either in collision function or when adding them to the obstacles list
    # goal_func - default to not needing


MOVED ALL RRT FUNCTIONS TO SEPERATE PY FILE

 
Borrowed some code to run execution and results:
Base of robot will need to be driven forward and be know such that the appropriate goal can be established based on robot reference frame. Action looks good. Step size of 0.1 provides jerky but acceptable motion plan.

TODO: - determine what positions are required to get to each action (and base location)
      - write function to run rrt for each action as it is planned
      - figure out how to move an object with the arm

Wrote function to drive robot base to certain location with passable graphics. Reccomended start position is [0.75,0.65, np.pi]. Also added dictionary with the goal poses so a list of actions can be used to run a series of actions. In the future plan to parse the activity planner output for the first, second, etc. The first word being the action can be directed at different actions, with the second and beyond telling which of the goals to use

Very simple implimentation to move an object, just capture link and refresh position every step of the arm. Has a bug that the object jumps right when it is graps

Drawer opens in kinda shitty motion via linear steps of its position at the same time the gripper moves from the open spot to the close spot. Assume a flexible drawer handle that does not need to be rigidly grapsed. Could use IK in cartesian space to get smooth movement that would be non-linear in configuration space

Hardcoded activities list with success. Previously mentioned issues with the drawer opening not being smooth or directly correlated. Similarly the issue with pose changing when an item is picked up. Perhaps create an action for the pickup and drop with changes the angle of the object to match the flat surface? Video recorded as motion_planning_hardcode.mp4



Future Thoughts:
create dictionary of locations and their respective locations and use the second/third/fourth word of input argument to get the targets for each action.
minimal example uses format of having a get_XXXXX_func to create functions so i guess that must be the best way to do it

Getting into collision with 3? unknown what it is. 0 is kitchen_part_right. 1 is "plane". 2 is world.robot. 3 might be either sugar box or potten meat can1. Unclear whatever they might be it appears need to ignore 3 and 4 and 5 at minimum.

Sugar = 4
Spam = 5?

Kitchen Joints:
27 dagger_door_left_joint
56 indigo_drawer_top_joint
58 indigo_drawer_bottom_joint


WTF is a quat? required for many of the built in functions for comparing poses


move_arm - robot, from, to
open_door - robot, to, None
release_thing -  robot, loc, item
grab_thing - robot, loc, item
move_object robot, from, to, 


Not all global settings worked = importing on a nother doesnt seem viable Same vitals included in headers of several files. Had to hardcode the obstacles to not count. Kinda messy way of doing it since it requires so many dictionary entries, but it keeps the main code cleaner.